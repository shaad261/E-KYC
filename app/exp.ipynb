{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5730 2300 6317']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Update the path if tesseract is not installed in the default path\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def image_to_array(image_path):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Use pytesseract to do OCR on the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    \n",
    "    # Convert the text into an array of lines or words\n",
    "    # Split by lines to get an array of each line in the text\n",
    "    lines_array = text.splitlines()\n",
    "    \n",
    "    # Convert the array to a numpy array if desired\n",
    "    lines_array = np.array(lines_array)\n",
    "    \n",
    "    return lines_array\n",
    "\n",
    "# Usage example\n",
    "image_path = 'test/front.png'\n",
    "front_text_array = image_to_array(image_path)\n",
    "print(front_text_array[[8]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SER Fears wr TAT B, ATT aT eae aT ET',\n",
       "       'Feo Goa wears (sees Taree, UT YS HS /',\n",
       "       'aime wRacace ht ean) a ares fae ora artes |', '',\n",
       "       'Aadhaar is proof of identity, not of citizenship',\n",
       "       'or date of birth. It should be used with verification (online',\n",
       "       'authentication, or scanning of QR code / offline XML).', '',\n",
       "       '5730 2300 6317', 'ART arene, ALT Geadiet', ''], dtype='<U61')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front_text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str(front_text_array[[12]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ua:' '' 'AGE seh, OT -9, TS aL, Gage sie' '' 'gars - 831012' '=Address:'\n",
      " 'SMaqsood Ali, H NO -1, ROAD NO 18, J KS' 'SCOLONY JAWAHARNAGAR MANGO'\n",
      " 'JAMSHEDPUR, Jamshedpur, PO: Mango,' '¥bist- East Singhbhum,'\n",
      " '© Jharkhand - 831012' '' '(=' '' '5730 2300 6317'\n",
      " 'VID : 9140 2246 3221 3628' ''\n",
      " 'Ge ics7 | 4 help@uidal.gov.in | GD www.uidal.gov.in']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Update the path if tesseract is not installed in the default path\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def image_to_array(image_path):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Use pytesseract to do OCR on the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    \n",
    "    # Convert the text into an array of lines or words\n",
    "    # Split by lines to get an array of each line in the text\n",
    "    lines_array = text.splitlines()\n",
    "    \n",
    "    # Convert the array to a numpy array if desired\n",
    "    lines_array = np.array(lines_array)\n",
    "    \n",
    "    return lines_array\n",
    "\n",
    "# Usage example\n",
    "image_path = 'test/back.png'\n",
    "back_text_array = image_to_array(image_path)\n",
    "print(back_text_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ua:  AGE seh, OT -9, TS aL, Gage sie  gars - 831012 =Address: SMaqsood Ali, H NO -1, ROAD NO 18, J KS SCOLONY JAWAHARNAGAR MANGO JAMSHEDPUR, Jamshedpur, PO: Mango, ¥bist- East Singhbhum, © Jharkhand - 831012  (=  5730 2300 6317 VID : 9140 2246 3221 3628  Ge ics7 | 4 help@uidal.gov.in | GD www.uidal.gov.in'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SMaqsood Ali, H NO -1, ROAD NO 18, J KS' 'SCOLONY JAWAHARNAGAR MANGO'\n",
      " 'JAMSHEDPUR, Jamshedpur, PO: Mango,' '¥bist- East Singhbhum,'\n",
      " '© Jharkhand - 831012' '' '(=' '']\n"
     ]
    }
   ],
   "source": [
    "ntext=back_text_array[6:14]\n",
    "print(ntext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMaqsood Ali, H NO -1, ROAD NO 18, J KS SCOLONY JAWAHARNAGAR MANGO JAMSHEDPUR, Jamshedpur, PO: Mango, ¥bist- East Singhbhum, © Jharkhand - 831012  (= \n"
     ]
    }
   ],
   "source": [
    "ctext = ' '.join(ntext)\n",
    "print(ctext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ali H NO 1 ROAD NO 18 J KS SCOLONY JAWAHARNAGAR MANGO JAMSHEDPUR Jamshedpur PO Mango bist East Singhbhum  Jharkhand  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Join array elements into a single string\n",
    "back_text_array_str = ' '.join(back_text_array)\n",
    "\n",
    "# Regular expression with capture groups\n",
    "pattern = r'Address(.*?)(\\b\\w+\\b)(.*?)831012'\n",
    "\n",
    "# Capture all text except the first word after address and special characters\n",
    "match = re.search(pattern, text)\n",
    "\n",
    "if match:\n",
    "  # Group 1: Text before the first word after address\n",
    "  address_text = match.group(1)\n",
    "  # Group 3: Text after the first word (excluding special characters)\n",
    "  main_text = re.sub(r\"[^\\w\\s]\", \"\", match.group(3))\n",
    "\n",
    "  # Combine and print the desired text\n",
    "  print(main_text)\n",
    "else:\n",
    "  print(\"Pattern not found.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ali H NO 1 ROAD NO 18 J KS SCOLONY JAWAHARNAGAR MANGO JAMSHEDPUR Jamshedpur PO Mango bist East Singhbhum  Jharkhand  '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SMaqsood Ali, H NO -1, ROAD NO 18, J KS SCOLONY JAWAHARNAGAR MANGO JAMSHEDPUR, Jamshedpur, PO: Mango, ¥bist- East Singhbhum, © Jharkhand - 831012  (= '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Similarity: 0.7866666666666666\n",
      "Jaccard Similarity: 0.9591663046625443\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def levenshtein_similarity(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    similarity = 1 - distance / max_len\n",
    "    return similarity\n",
    "\n",
    "def jaccard_similarity(str1, str2):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectors = vectorizer.fit_transform([str1, str2])\n",
    "    similarity = cosine_similarity(vectors)[0, 1]\n",
    "    return similarity\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "levenshtein_sim = levenshtein_similarity(ctext, main_text)\n",
    "jaccard_sim = jaccard_similarity(ctext, main_text)\n",
    "\n",
    "print(\"Levenshtein Similarity:\", levenshtein_sim)\n",
    "print(\"Jaccard Similarity:\", jaccard_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtein Distance:\n",
    "\n",
    "Calculates the minimum number of edits (insertions, deletions, substitutions) required to transform one string into another.\n",
    "A lower distance indicates higher similarity.\n",
    "The similarity score is calculated as 1 - (distance / max_length).\n",
    "Jaccard Similarity:\n",
    "\n",
    "Converts strings into numerical representations using a vectorizer.\n",
    "Calculates the cosine similarity between the two vectors, which measures the cosine of the angle between them.\n",
    "A higher cosine similarity indicates higher similarity.\n",
    "Choosing the Right Metric:\n",
    "\n",
    "Levenshtein Distance: Suitable for comparing strings with minor differences, such as typos or small variations.\n",
    "Jaccard Similarity: Better for comparing strings with semantic similarity, where the meaning of the words is more important than the exact word order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Levenshtein similarity score of 0.7866666666666666 indicates that the two strings are relatively similar. This means that a relatively small number of edits (insertions, deletions, or substitutions) are required to transform one string into the other.\n",
    "\n",
    "Here's a breakdown of how the score is calculated:\n",
    "\n",
    "Levenshtein Distance:\n",
    "\n",
    "This measures the minimum number of edits needed to transform one string into another.\n",
    "A lower distance indicates higher similarity.\n",
    "Similarity Calculation:\n",
    "\n",
    "The similarity score is calculated using the formula:\n",
    "similarity = 1 - (distance / max_len)\n",
    "distance is the Levenshtein distance.\n",
    "max_len is the maximum length of the two strings.\n",
    "A higher similarity score, like 0.7866666666666666, suggests that the two strings have a substantial overlap in their characters and overall structure.\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider these two strings:\n",
    "\n",
    "String 1: \"hello world\"\n",
    "String 2: \"hello world!\"\n",
    "The Levenshtein distance between these two strings is 1, as only one edit (adding an exclamation point) is required to transform String 1 into String 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from re import T\n",
    "import active_liveness\n",
    "import streamlit as st\n",
    "# from streamlit import legacy_caching\n",
    "from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, ClientSettings\n",
    "import cv2\n",
    "import av\n",
    "import numpy as np\n",
    "from ocr.back_side_parse import get_info_back, get_string_similarity\n",
    "import datetime\n",
    "\n",
    "import os, sys\n",
    "from active_liveness import headpose_liveness\n",
    "\n",
    "my_absolute_dirpath = os.path.abspath(os.path.dirname(__file__))\n",
    "sys.path.insert(0, my_absolute_dirpath + '/passive_liveness')\n",
    "from passive_liveness import predict_liveness\n",
    "\n",
    "sys.path.insert(0, my_absolute_dirpath + '/face')\n",
    "from face import dnn_face_detection, find_face_similarity\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from re import T\n",
    "import active_liveness\n",
    "import streamlit as st\n",
    "# from streamlit import legacy_caching\n",
    "from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, ClientSettings\n",
    "import cv2\n",
    "import av\n",
    "import numpy as np\n",
    "from ocr.back_side_parse import get_info_back, get_string_similarity\n",
    "import datetime\n",
    "\n",
    "import os, sys\n",
    "from active_liveness import headpose_liveness\n",
    "\n",
    "my_absolute_dirpath = os.path.abspath(os.path.dirname(__file__))\n",
    "sys.path.insert(0, my_absolute_dirpath + '/passive_liveness')\n",
    "from passive_liveness import predict_liveness\n",
    "\n",
    "sys.path.insert(0, my_absolute_dirpath + '/face')\n",
    "from face import dnn_face_detection, find_face_similarity\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import T\n",
    "import active_liveness\n",
    "import streamlit as st\n",
    "# from streamlit import legacy_caching\n",
    "from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, ClientSettings\n",
    "import cv2\n",
    "import av\n",
    "import numpy as np\n",
    "from ocr.back_side_parse import get_info_back, get_string_similarity\n",
    "import datetime\n",
    "\n",
    "import os, sys\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "citizenship_front = cv2.imread(\"test/front.png\")\n",
    "citizenship_back = cv2.imread(\"test/back.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image1_path = 'test/front.png'\n",
    "image2_path = 'test/back.png'\n",
    "\n",
    "img1 = cv2.imread(image1_path)\n",
    "if img1 is None:\n",
    "    print(\"Error: Could not load image:\", image1_path)\n",
    "    exit()\n",
    "\n",
    "img2 = cv2.imread(image2_path)\n",
    "if img2 is None:\n",
    "    print(\"Error: Could not load image:\", image2_path)\n",
    "    exit()\n",
    "\n",
    "def get_info_back(image):\n",
    "    \"\"\"Returns all the information from input image\n",
    "\n",
    "    Args:\n",
    "        image (ndarray): input image\n",
    "\n",
    "    Returns:\n",
    "        dic: information from the input image\n",
    "    \"\"\"\n",
    "    # os.environ[\"TESSDATA_PREFIX\"] = r\"C:\\Program Files\\Tesseract-OCR\\tessdata\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    text = pytesseract.image_to_string(image, lang='eng')\n",
    "    text = [line for line in text.split('\\n') if line.strip() != '']\n",
    "\n",
    "    info = {}\n",
    "\n",
    "    # cnText = [i.split(' ') for i in text]\n",
    "    cnText = []\n",
    "    for i in text:\n",
    "        ct = i.split(' ')\n",
    "        ct = [re.sub(\"[$&+,:;=?@#|'<>.^*()%!-]\", '', c) for c in ct]\n",
    "        ct = list(filter(None, ct))\n",
    "        cnText.append(ct)\n",
    "    \n",
    "    return cnText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = get_info_back(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aadhaar', 'no', 'issued', '24/10/2013'],\n",
       " ['ana', 'BHT'],\n",
       " ['Government', 'of', 'India'],\n",
       " ['e', 'ett'],\n",
       " ['Shaad', 'Ali'],\n",
       " ['a', 'fafei/DOB', '08/08/2003'],\n",
       " ['gee/', 'MALE'],\n",
       " ['Sea', 'ears', 'wr', 'TAT', 'arr', 'at', 'reafefer', 'a', 'eT'],\n",
       " ['wee', 'STENT', 'wears', 'site', 'Tae', 'aT', 'YSN', 'wrS/'],\n",
       " ['Simons', 'wracace', 'at', 'eft', 'a', 'ares', 'fen', 'ot', 'aTfey'],\n",
       " ['Aadhaar', 'is', 'proof', 'of', 'identity', 'not', 'of', 'citizenship'],\n",
       " ['or',\n",
       "  'date',\n",
       "  'of',\n",
       "  'birth',\n",
       "  'It',\n",
       "  'should',\n",
       "  'be',\n",
       "  'used',\n",
       "  'with',\n",
       "  'verification',\n",
       "  'online'],\n",
       " ['authentication',\n",
       "  'or',\n",
       "  'scanning',\n",
       "  'of',\n",
       "  'QR',\n",
       "  'code',\n",
       "  '/',\n",
       "  'offline',\n",
       "  'XML'],\n",
       " ['5730', '2300', '6317'],\n",
       " ['Art', 'aem', 'AN', 'veut']]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_list_regex(data, pattern):\n",
    "    target_list = []\n",
    "    for sublist in data:\n",
    "        # Join the sublist into a string and search for the pattern\n",
    "        joined_str = ' '.join(sublist)\n",
    "        match = re.findall(pattern, joined_str)\n",
    "        \n",
    "        # If there are exactly 3 matches, add it to the result list\n",
    "        if len(match) == 3:\n",
    "            target_list.append(match)\n",
    "    \n",
    "    return target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5730', '2300', '6317']]\n"
     ]
    }
   ],
   "source": [
    "target_pattern = r'\\b\\d{4}\\b'\n",
    "\n",
    "# Find the target list using the regex pattern\n",
    "target_list = find_target_list_regex(info, target_pattern)\n",
    "\n",
    "# Output the result\n",
    "print(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5730 2300 6317\n"
     ]
    }
   ],
   "source": [
    "result = ' '.join(target_list[0])\n",
    "# Output the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "info1 = get_info_back(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bd', 'ade', 'fake', 'gear', 'wiitraror', '~'],\n",
       " ['Unique', 'Identification', 'Authority', 'of', 'India', 'ZAM'],\n",
       " ['Ua'],\n",
       " ['FORE', 'Het', 'Far', 'A', '9', 'Us', '9c', 'Sears', 'sie'],\n",
       " ['gerers', '831012'],\n",
       " ['Address'],\n",
       " ['SMaqsood', 'Ali', 'H', 'NO', '1', 'ROAD', 'NO', '18', 'KS'],\n",
       " ['COLONY', 'JAWAHARNAGAR', 'MANGO'],\n",
       " ['JAMSHEDPUR', 'Jamshedpur', 'PO', 'Mango'],\n",
       " ['3bist', 'East', 'Singhbhum'],\n",
       " ['©', 'Jharkhand', '831012'],\n",
       " ['5730', '2300', '6317'],\n",
       " ['VID', '9140', '2246', '3221', '3628'],\n",
       " ['Geics7_', '4', 'helpuidalgovin', 'GD', 'wwwuidalgovin']]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMaqsood Ali H NO 1 ROAD NO 18 KSCOLONY JAWAHARNAGAR MANGOJAMSHEDPUR Jamshedpur PO Mango3bist East Singhbhum© Jharkhand 831012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the variable L (which will be set dynamically)\n",
    "L = result   # Modify this as needed\n",
    "\n",
    "# Flatten the list and join each inner list without spaces\n",
    "flattened_list = [' '.join(sublist) for sublist in info1]\n",
    "\n",
    "# Find the index of \"Address\" and L in the flattened list\n",
    "address_index = flattened_list.index('Address')\n",
    "try:\n",
    "    L_index = flattened_list.index(L)\n",
    "except ValueError:\n",
    "    L_index = None  # Handle case where L is not found\n",
    "\n",
    "# Extract elements between \"Address\" and L\n",
    "if L_index and L_index > address_index:\n",
    "    result1 = ''.join(flattened_list[address_index + 1 : L_index])  # Join elements between Address and L\n",
    "else:\n",
    "    result1 = \"\"  # If L is not found or not in the correct order\n",
    "\n",
    "# Output the result\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
